{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kingsleykimm/quantumneuralnetwork/blob/main/QNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5V4wr7jX4-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1f8f8d9-c998-4687-f284-f3b23345bb58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.7.0\n",
            "  Downloading tensorflow-2.7.0-cp37-cp37m-manylinux2010_x86_64.whl (489.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 489.6 MB 22 kB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.0.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (0.37.1)\n",
            "Collecting tensorflow-estimator<2.8,~=2.7.0rc0\n",
            "  Downloading tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n",
            "\u001b[K     |████████████████████████████████| 463 kB 69.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (3.3.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.44.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.1.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (2.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (14.0.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (3.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (0.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.15.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (2.8.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.14.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (4.2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (0.25.0)\n",
            "Collecting gast<0.5.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Collecting keras<2.8,>=2.7.0rc0\n",
            "  Downloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 39.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (3.17.3)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.21.6)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow==2.7.0) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (3.3.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.35.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (57.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7.0) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7.0) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0) (3.2.0)\n",
            "Installing collected packages: tensorflow-estimator, keras, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.0\n",
            "    Uninstalling tensorflow-2.8.0:\n",
            "      Successfully uninstalled tensorflow-2.8.0\n",
            "Successfully installed gast-0.4.0 keras-2.7.0 tensorflow-2.7.0 tensorflow-estimator-2.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.7.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-quantum"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Z4vQ7xs-X7u9",
        "outputId": "2cdda30f-b80d-4169-a57e-e695a0300860"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-quantum\n",
            "  Downloading tensorflow_quantum-0.6.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (10.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.5 MB 6.8 MB/s \n",
            "\u001b[?25hCollecting sympy==1.8\n",
            "  Downloading sympy-1.8-py3-none-any.whl (6.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.1 MB 37.4 MB/s \n",
            "\u001b[?25hCollecting google-api-core==1.21.0\n",
            "  Downloading google_api_core-1.21.0-py2.py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 8.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf==3.17.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-quantum) (3.17.3)\n",
            "Collecting cirq-google>=0.13.1\n",
            "  Downloading cirq_google-0.14.1-py3-none-any.whl (541 kB)\n",
            "\u001b[K     |████████████████████████████████| 541 kB 26.7 MB/s \n",
            "\u001b[?25hCollecting googleapis-common-protos==1.52.0\n",
            "  Downloading googleapis_common_protos-1.52.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[K     |████████████████████████████████| 100 kB 6.5 MB/s \n",
            "\u001b[?25hCollecting cirq-core>=0.13.1\n",
            "  Downloading cirq_core-0.14.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 38.4 MB/s \n",
            "\u001b[?25hCollecting google-auth==1.18.0\n",
            "  Downloading google_auth-1.18.0-py2.py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 10.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=34.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core==1.21.0->tensorflow-quantum) (57.4.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core==1.21.0->tensorflow-quantum) (1.15.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core==1.21.0->tensorflow-quantum) (2.23.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core==1.21.0->tensorflow-quantum) (2022.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth==1.18.0->tensorflow-quantum) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth==1.18.0->tensorflow-quantum) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth==1.18.0->tensorflow-quantum) (4.2.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy==1.8->tensorflow-quantum) (1.2.1)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.7/dist-packages (from cirq-core>=0.13.1->tensorflow-quantum) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from cirq-core>=0.13.1->tensorflow-quantum) (1.3.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cirq-core>=0.13.1->tensorflow-quantum) (4.2.0)\n",
            "Requirement already satisfied: sortedcontainers~=2.0 in /usr/local/lib/python3.7/dist-packages (from cirq-core>=0.13.1->tensorflow-quantum) (2.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from cirq-core>=0.13.1->tensorflow-quantum) (4.64.0)\n",
            "Collecting backports.cached-property~=1.0.1\n",
            "  Downloading backports.cached_property-1.0.1-py3-none-any.whl (5.7 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from cirq-core>=0.13.1->tensorflow-quantum) (1.4.1)\n",
            "Requirement already satisfied: numpy~=1.16 in /usr/local/lib/python3.7/dist-packages (from cirq-core>=0.13.1->tensorflow-quantum) (1.21.6)\n",
            "Requirement already satisfied: networkx~=2.4 in /usr/local/lib/python3.7/dist-packages (from cirq-core>=0.13.1->tensorflow-quantum) (2.6.3)\n",
            "Collecting duet~=0.2.0\n",
            "  Downloading duet-0.2.6-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from cirq-google>=0.13.1->tensorflow-quantum) (1.31.5)\n",
            "Collecting typing-extensions\n",
            "  Downloading typing_extensions-3.10.0.0-py3-none-any.whl (26 kB)\n",
            "Collecting google-api-core[grpc]<2.0.0dev,>=1.14.0\n",
            "  Downloading google_api_core-1.31.4-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 969 kB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.31.3-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 1.2 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.31.2-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 1.5 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.31.1-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 882 kB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.31.0-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 1.1 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.30.0-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 1.5 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.29.0-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 644 kB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.28.0-py2.py3-none-any.whl (92 kB)\n",
            "\u001b[K     |████████████████████████████████| 92 kB 1.2 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.27.0-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 1.4 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.26.3-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 1.3 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.26.2-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 1.2 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.26.1-py2.py3-none-any.whl (92 kB)\n",
            "\u001b[K     |████████████████████████████████| 92 kB 1.1 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.26.0-py2.py3-none-any.whl (92 kB)\n",
            "\u001b[K     |████████████████████████████████| 92 kB 1.1 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.25.1-py2.py3-none-any.whl (92 kB)\n",
            "\u001b[K     |████████████████████████████████| 92 kB 214 kB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.25.0-py2.py3-none-any.whl (92 kB)\n",
            "\u001b[K     |████████████████████████████████| 92 kB 82 kB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.24.1-py2.py3-none-any.whl (92 kB)\n",
            "\u001b[K     |████████████████████████████████| 92 kB 6.1 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.24.0-py2.py3-none-any.whl (91 kB)\n",
            "\u001b[K     |████████████████████████████████| 91 kB 5.2 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.23.0-py2.py3-none-any.whl (91 kB)\n",
            "\u001b[K     |████████████████████████████████| 91 kB 5.5 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.22.4-py2.py3-none-any.whl (91 kB)\n",
            "\u001b[K     |████████████████████████████████| 91 kB 6.4 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.22.3-py2.py3-none-any.whl (91 kB)\n",
            "\u001b[K     |████████████████████████████████| 91 kB 4.7 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.22.2-py2.py3-none-any.whl (91 kB)\n",
            "\u001b[K     |████████████████████████████████| 91 kB 9.7 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.22.1-py2.py3-none-any.whl (91 kB)\n",
            "\u001b[K     |████████████████████████████████| 91 kB 9.7 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.22.0-py2.py3-none-any.whl (91 kB)\n",
            "\u001b[K     |████████████████████████████████| 91 kB 9.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio<2.0dev,>=1.29.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core==1.21.0->tensorflow-quantum) (1.44.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib~=3.0->cirq-core>=0.13.1->tensorflow-quantum) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib~=3.0->cirq-core>=0.13.1->tensorflow-quantum) (1.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib~=3.0->cirq-core>=0.13.1->tensorflow-quantum) (3.0.8)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib~=3.0->cirq-core>=0.13.1->tensorflow-quantum) (2.8.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth==1.18.0->tensorflow-quantum) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core==1.21.0->tensorflow-quantum) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core==1.21.0->tensorflow-quantum) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core==1.21.0->tensorflow-quantum) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core==1.21.0->tensorflow-quantum) (2.10)\n",
            "Installing collected packages: typing-extensions, googleapis-common-protos, google-auth, sympy, google-api-core, duet, backports.cached-property, cirq-core, cirq-google, tensorflow-quantum\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.2.0\n",
            "    Uninstalling typing-extensions-4.2.0:\n",
            "      Successfully uninstalled typing-extensions-4.2.0\n",
            "  Attempting uninstall: googleapis-common-protos\n",
            "    Found existing installation: googleapis-common-protos 1.56.0\n",
            "    Uninstalling googleapis-common-protos-1.56.0:\n",
            "      Successfully uninstalled googleapis-common-protos-1.56.0\n",
            "  Attempting uninstall: google-auth\n",
            "    Found existing installation: google-auth 1.35.0\n",
            "    Uninstalling google-auth-1.35.0:\n",
            "      Successfully uninstalled google-auth-1.35.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.7.1\n",
            "    Uninstalling sympy-1.7.1:\n",
            "      Successfully uninstalled sympy-1.7.1\n",
            "  Attempting uninstall: google-api-core\n",
            "    Found existing installation: google-api-core 1.31.5\n",
            "    Uninstalling google-api-core-1.31.5:\n",
            "      Successfully uninstalled google-api-core-1.31.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pydata-google-auth 1.4.0 requires google-auth<3.0dev,>=1.25.0; python_version >= \"3.6\", but you have google-auth 1.18.0 which is incompatible.\n",
            "google-cloud-bigquery-storage 1.1.1 requires google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5, but you have google-api-core 1.21.0 which is incompatible.\u001b[0m\n",
            "Successfully installed backports.cached-property-1.0.1 cirq-core-0.14.1 cirq-google-0.14.1 duet-0.2.6 google-api-core-1.21.0 google-auth-1.18.0 googleapis-common-protos-1.52.0 sympy-1.8 tensorflow-quantum-0.6.1 typing-extensions-3.10.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "# import tensorflow_quantum as tfq\n",
        "from tensorflow.keras import datasets, layers, models, optimizers\n",
        "from sklearn.model_selection import KFold\n",
        "import random\n",
        "\n",
        "# import cirq\n",
        "# import sympy\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import collections\n",
        "\n",
        "# visualization tools\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "# from cirq.contrib.svg import SVGCircuit"
      ],
      "metadata": {
        "id": "V4sdTewuZWis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_diversity(current_x, current_y, block_arr, corresponding_number, num_per_each_block, quantum):\n",
        "  temp_x = list()\n",
        "  temp_y = list()\n",
        "  for block in block_arr:\n",
        "    temp_block = np.ndarray.flatten(block)\n",
        "    for x in range(num_per_each_block):\n",
        "      random_generated = [random.uniform(0.7, 1.0) if pixel == 255 else random.uniform(0.0, 0.1) for pixel in temp_block]\n",
        "      if not quantum:\n",
        "        random_generated = np.array(random_generated).reshape((4, 4))\n",
        "      temp_x.append(random_generated)\n",
        "      temp_y.append(corresponding_number)\n",
        "  \n",
        "  temp_x = np.array(temp_x)\n",
        "  temp_y = np.array(temp_y)\n",
        "  current_x = np.concatenate((current_x, temp_x))\n",
        "  current_y = np.concatenate((current_y, temp_y))\n",
        "  return current_x, current_y"
      ],
      "metadata": {
        "id": "EK447SN0e6Tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#read images here\n",
        "import os \n",
        "from PIL import Image\n",
        "import glob\n",
        "import random\n",
        "image = np.empty(0)\n",
        "cube_arr = np.array([])\n",
        "diagonal_arr = np.array([])\n",
        "l_arr = np.array([])\n",
        "line_arr = np.array([])\n",
        "table_arr = np.array([])\n",
        "quantum = True\n",
        "classical = False\n",
        "\n",
        "# NOTE CUBE:1  DIAGONAL:2  L:3  LINE:4  TABLE:5\n",
        "for filename in glob.glob('/content/Tetris Images/*.png'): #assuming gif\n",
        "  if \"Cube\" in filename:\n",
        "    im = Image.open(filename).convert(\"L\")\n",
        "    pix_array = np.array(im.getdata()).reshape((4, 4))\n",
        "    pix_array = np.array([pix_array])\n",
        "    if cube_arr.size == 0:\n",
        "      cube_arr = np.array(pix_array)\n",
        "    else:\n",
        "      cube_arr = np.vstack([cube_arr, pix_array])\n",
        "  \n",
        "  if \"Diagonal\" in filename:\n",
        "    im = Image.open(filename).convert(\"L\")\n",
        "    pix_array = np.array(im.getdata()).reshape((4, 4))\n",
        "    pix_array = np.array([pix_array])\n",
        "    if diagonal_arr.size == 0:\n",
        "      diagonal_arr = np.array(pix_array)\n",
        "    else:\n",
        "      diagonal_arr = np.vstack([diagonal_arr, pix_array])\n",
        "  \n",
        "  if \"L\" in filename:\n",
        "    im = Image.open(filename).convert(\"L\")\n",
        "    pix_array = np.array(im.getdata()).reshape((4, 4))\n",
        "    pix_array = np.array([pix_array])\n",
        "    if l_arr.size == 0:\n",
        "      l_arr = np.array(pix_array)\n",
        "    else:\n",
        "      l_arr = np.vstack([l_arr, pix_array])\n",
        "  \n",
        "  if \"line\" in filename:\n",
        "    im = Image.open(filename).convert(\"L\")\n",
        "    pix_array = np.array(im.getdata()).reshape((4, 4))\n",
        "    pix_array = np.array([pix_array])\n",
        "    if line_arr.size == 0:\n",
        "      line_arr = np.array(pix_array)\n",
        "    else:\n",
        "      line_arr = np.vstack([line_arr, pix_array])\n",
        "  \n",
        "  if \"Table\" in filename:\n",
        "    im = Image.open(filename).convert(\"L\")\n",
        "    pix_array = np.array(im.getdata()).reshape((4, 4))\n",
        "    pix_array = np.array([pix_array])\n",
        "    if table_arr.size == 0:\n",
        "      table_arr = np.array(pix_array)\n",
        "    else:\n",
        "      table_arr = np.vstack([table_arr, pix_array])\n",
        "\n",
        "\n",
        "#################################### THIS IS FOR ADDITION OF NOISE FOR NORMAL\n",
        "full_composition_trainX = np.concatenate((cube_arr, diagonal_arr, l_arr, line_arr, table_arr))/255\n",
        "full_composition_trainY = np.concatenate((np.full(9, 1, dtype=int), np.full(24, 2, dtype=int), np.full(48, 3, dtype=int), np.full(8, 4, dtype=int), np.full(24, 5, dtype=int)))\n",
        "full_composition_trainX, full_composition_trainY = add_diversity(full_composition_trainX, full_composition_trainY, cube_arr, 1, 176, classical)\n",
        "full_composition_trainX, full_composition_trainY = add_diversity(full_composition_trainX, full_composition_trainY, diagonal_arr, 2, 64, classical)\n",
        "full_composition_trainX, full_composition_trainY = add_diversity(full_composition_trainX, full_composition_trainY, l_arr, 3, 32, classical)\n",
        "full_composition_trainX, full_composition_trainY = add_diversity(full_composition_trainX, full_composition_trainY, line_arr, 4, 176, classical)\n",
        "full_composition_trainX, full_composition_trainY = add_diversity(full_composition_trainX, full_composition_trainY, table_arr, 5, 64, classical)\n",
        "print(full_composition_trainX)\n",
        "print(full_composition_trainY)\n",
        "plt.imshow(full_composition_trainX[5067], vmin=0, vmax=1)\n",
        "plt.colorbar()\n",
        "\n",
        "#################################### THIS IS FOR ORIGINAL ORIGINAL\n",
        "# full_composition_trainX = np.concatenate((cube_arr, diagonal_arr, l_arr, line_arr, table_arr))/255\n",
        "# full_composition_trainY = np.concatenate((np.full(9, 1, dtype=int), np.full(24, 2, dtype=int), np.full(48, 3, dtype=int), np.full(8, 4, dtype=int), np.full(24, 5, dtype=int)))\n",
        "\n",
        "\n",
        "##################################### THIS IS FOR ORIGINAL FILTERING\n",
        "# filtered_trainX = np.concatenate((cube_arr[np.random.choice(cube_arr.shape[0], 9, replace=False)],\n",
        "#                                  diagonal_arr[np.random.choice(diagonal_arr.shape[0], 10, replace=False)],\n",
        "#                                  l_arr[np.random.choice(l_arr.shape[0], 10, replace=False)],\n",
        "#                                  line_arr[np.random.choice(line_arr.shape[0], 8, replace=False)],\n",
        "#                                  table_arr[np.random.choice(table_arr.shape[0], 10, replace=False)]))/255\n",
        "\n",
        "# filtered_trainY = np.concatenate((np.full(9, 1, dtype=int),\n",
        "#                                   np.full(10, 2, dtype=int),\n",
        "#                                   np.full(10, 3, dtype=int),\n",
        "#                                   np.full(8, 4, dtype=int),\n",
        "#                                   np.full(10, 5, dtype=int)))\n",
        "\n",
        "\n",
        "#################################### THIS IS FOR EXPANDING LIMITED BLOCKS (CUBES AND LINES)\n",
        "# filtered_trainX = np.concatenate((cube_arr[np.random.choice(cube_arr.shape[0], 24, replace=True)],\n",
        "#                                  diagonal_arr[np.random.choice(diagonal_arr.shape[0], 24, replace=False)],\n",
        "#                                  l_arr[np.random.choice(l_arr.shape[0], 32, replace=False)],\n",
        "#                                  line_arr[np.random.choice(line_arr.shape[0], 24, replace=True)],\n",
        "#                                  table_arr[np.random.choice(table_arr.shape[0], 24, replace=False)]))/255\n",
        "\n",
        "# filtered_trainY = np.concatenate((np.full(24, 1, dtype=int),\n",
        "#                                   np.full(24, 2, dtype=int),\n",
        "#                                   np.full(32, 3, dtype=int),\n",
        "#                                   np.full(24, 4, dtype=int),\n",
        "#                                   np.full(24, 5, dtype=int)))\n",
        "\n",
        "################################## THIS IS FOR QUANTUM (ONLY CUBES AND LINES)\n",
        "# filtered_trainX = np.concatenate((cube_arr[np.random.choice(cube_arr.shape[0], 9, replace=False)],\n",
        "#                                  line_arr[np.random.choice(line_arr.shape[0], 8, replace=False)]))/255\n",
        "\n",
        "# filtered_trainY = np.concatenate((np.full(9, 3, dtype=int),\n",
        "#                                   np.full(8, 6, dtype=int)))\n",
        "\n",
        "# filtered_trainX = [np.ndarray.flatten(image) for image in filtered_trainX]\n",
        "# filtered_trainX = np.array(filtered_trainX)\n",
        "\n",
        "\n",
        "################################### THIS IS FOR QUANTUM WITH NOISE (ONLY CUBES AND LINES)\n",
        "# filtered_trainX = np.concatenate((cube_arr[np.random.choice(cube_arr.shape[0], 9, replace=False)],\n",
        "#                                  line_arr[np.random.choice(line_arr.shape[0], 8, replace=False)]))/255\n",
        "\n",
        "# filtered_trainY = np.concatenate((np.full(9, 3, dtype=int),\n",
        "#                                   np.full(8, 6, dtype=int)))\n",
        "\n",
        "# filtered_trainX = [np.ndarray.flatten(image) for image in filtered_trainX]\n",
        "# filtered_trainX = np.array(filtered_trainX)\n",
        "# print(filtered_trainX)\n",
        "# print(filtered_trainY)\n",
        "# filtered_trainX, filtered_trainY = add_diversity(filtered_trainX, filtered_trainY, cube_arr, 3, 560, quantum)\n",
        "# filtered_trainX, filtered_trainY = add_diversity(filtered_trainX, filtered_trainY, line_arr, 6, 560, quantum)"
      ],
      "metadata": {
        "id": "buwCnPfL7ROu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 842
        },
        "outputId": "51e92b6d-0d86-4946-f0b9-54dc6c86fcfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.        ]\n",
            "  [1.         1.         0.         0.        ]\n",
            "  [1.         1.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         1.         1.        ]\n",
            "  [0.         0.         1.         1.        ]\n",
            "  [0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.        ]]\n",
            "\n",
            " [[0.         0.         0.         0.        ]\n",
            "  [0.         0.         1.         1.        ]\n",
            "  [0.         0.         1.         1.        ]\n",
            "  [0.         0.         0.         0.        ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.00237934 0.03561366 0.09925374 0.01187415]\n",
            "  [0.0745548  0.06027704 0.87121959 0.02317503]\n",
            "  [0.01097727 0.988351   0.70485079 0.90677688]\n",
            "  [0.0901484  0.01069328 0.01373551 0.00344005]]\n",
            "\n",
            " [[0.02847368 0.01617967 0.07230372 0.00150994]\n",
            "  [0.03161639 0.02756264 0.89742754 0.0180787 ]\n",
            "  [0.08825536 0.92121215 0.89988046 0.91528788]\n",
            "  [0.05476409 0.06820793 0.02659951 0.00872868]]\n",
            "\n",
            " [[0.03703696 0.08401529 0.08762363 0.04251221]\n",
            "  [0.058285   0.04553524 0.85716344 0.04326842]\n",
            "  [0.05993855 0.98627373 0.92422772 0.70203671]\n",
            "  [0.06662467 0.01263062 0.0271072  0.08450469]]]\n",
            "[1 1 1 ... 5 5 5]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7f0ec6c5f810>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_circuit(image):\n",
        "    \"\"\"Encode truncated classical image into quantum datapoint.\"\"\"\n",
        "    values = np.ndarray.flatten(image)\n",
        "    qubits = cirq.GridQubit.rect(4, 4)\n",
        "    circuit = cirq.Circuit()\n",
        "    for i, value in enumerate(values):\n",
        "        if value:\n",
        "            circuit.append(cirq.X(qubits[i]))\n",
        "    return circuit\n",
        "\n",
        "\n",
        "x_train_circ = [convert_to_circuit(x) for x in filtered_trainX]\n"
      ],
      "metadata": {
        "id": "0cd99GDqVfMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_tfcirc = tfq.convert_to_tensor(x_train_circ)"
      ],
      "metadata": {
        "id": "v0Ts71YXVwTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CircuitLayerBuilder():\n",
        "    def __init__(self, data_qubits, readout):\n",
        "        self.data_qubits = data_qubits\n",
        "        self.readout = readout\n",
        "\n",
        "    def add_layer(self, circuit, gate, prefix):\n",
        "        for i, qubit in enumerate(self.data_qubits):\n",
        "            symbol = sympy.Symbol(prefix + '-' + str(i))\n",
        "            circuit.append(gate(qubit, self.readout)**symbol)"
      ],
      "metadata": {
        "id": "BuHkMCuxWGey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo_builder = CircuitLayerBuilder(data_qubits = cirq.GridQubit.rect(4,1),\n",
        "                                   readout=cirq.GridQubit(-1,-1))\n",
        "\n",
        "circuit = cirq.Circuit()\n",
        "demo_builder.add_layer(circuit, gate = cirq.XX, prefix='xx')\n",
        "SVGCircuit(circuit)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "EzuIgyJUWI-c",
        "outputId": "fcedaed7-6e3d-4180-865d-fb7fa166e1c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<cirq.contrib.svg.svg.SVGCircuit at 0x7f4e228287d0>"
            ],
            "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"522.59953125\" height=\"250.0\"><line x1=\"39.810625\" x2=\"492.59953125000004\" y1=\"25.0\" y2=\"25.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"492.59953125000004\" y1=\"75.0\" y2=\"75.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"492.59953125000004\" y1=\"125.0\" y2=\"125.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"492.59953125000004\" y1=\"175.0\" y2=\"175.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"492.59953125000004\" y1=\"225.0\" y2=\"225.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"129.99353515625\" x2=\"129.99353515625\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"230.73810546875004\" x2=\"230.73810546875004\" y1=\"25.0\" y2=\"125.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"331.48267578125007\" x2=\"331.48267578125007\" y1=\"25.0\" y2=\"175.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"432.22724609375007\" x2=\"432.22724609375007\" y1=\"25.0\" y2=\"225.0\" stroke=\"black\" stroke-width=\"3\" /><rect x=\"10.0\" y=\"5.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(-1, -1): </text><rect x=\"10.0\" y=\"55.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 0): </text><rect x=\"10.0\" y=\"105.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(1, 0): </text><rect x=\"10.0\" y=\"155.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(2, 0): </text><rect x=\"10.0\" y=\"205.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(3, 0): </text><rect x=\"89.62125\" y=\"55.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"129.99353515625\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^(xx-0)</text><rect x=\"89.62125\" y=\"5.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"129.99353515625\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"190.36582031250003\" y=\"105.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"230.73810546875004\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^(xx-1)</text><rect x=\"190.36582031250003\" y=\"5.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"230.73810546875004\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"291.11039062500004\" y=\"155.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"331.48267578125007\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^(xx-2)</text><rect x=\"291.11039062500004\" y=\"5.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"331.48267578125007\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"391.85496093750004\" y=\"205.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"432.22724609375007\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^(xx-3)</text><rect x=\"391.85496093750004\" y=\"5.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"432.22724609375007\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text></svg>"
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_quantum_model():\n",
        "    \"\"\"Create a QNN model circuit and readout operation to go along with it.\"\"\"\n",
        "    data_qubits = cirq.GridQubit.rect(4, 4)  # a 4x4 grid.\n",
        "    readout = cirq.GridQubit(-1, -1)         # a single qubit at [-1,-1]\n",
        "    circuit = cirq.Circuit()\n",
        "\n",
        "    # Prepare the readout qubit.\n",
        "    circuit.append(cirq.X(readout))\n",
        "    circuit.append(cirq.H(readout))\n",
        "\n",
        "    builder = CircuitLayerBuilder(\n",
        "        data_qubits = data_qubits,\n",
        "        readout=readout)\n",
        "\n",
        "    # Then add layers (experiment by adding more).\n",
        "    builder.add_layer(circuit, cirq.XX, \"xx1\")\n",
        "    builder.add_layer(circuit, cirq.ZZ, \"zz1\")\n",
        "\n",
        "    # Finally, prepare the readout qubit.\n",
        "    circuit.append(cirq.H(readout))\n",
        "\n",
        "    return circuit, cirq.Z(readout)"
      ],
      "metadata": {
        "id": "1aBlU8N6WMEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_circuit, model_readout = create_quantum_model()"
      ],
      "metadata": {
        "id": "mENefTO6WSMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the Keras model.\n",
        "model = tf.keras.Sequential([\n",
        "    # The input is the data-circuit, encoded as a tf.string\n",
        "    tf.keras.layers.Input(shape=(), dtype=tf.string),\n",
        "    # The PQC layer returns the expected value of the readout gate, range [-1,1].\n",
        "    tfq.layers.PQC(model_circuit, model_readout),\n",
        "])"
      ],
      "metadata": {
        "id": "tkvfnQ9zWOPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_hinge = 2.0*filtered_trainY-1.0"
      ],
      "metadata": {
        "id": "WX4m_bQeZJgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hinge_accuracy(y_true, y_pred):\n",
        "    y_true = tf.squeeze(y_true) > 0.0\n",
        "    y_pred = tf.squeeze(y_pred) > 0.0\n",
        "    result = tf.cast(y_true == y_pred, tf.float32)\n",
        "\n",
        "    return tf.reduce_mean(result)"
      ],
      "metadata": {
        "id": "DOwzDfRmZWGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss=tf.keras.losses.Hinge(),\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=[hinge_accuracy])"
      ],
      "metadata": {
        "id": "mbWUx9OiZYs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZF4C9iiBZbo8",
        "outputId": "2a8f0f3b-b097-4a35-eae5-2eb19d03938f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_40\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " pqc_3 (PQC)                 (None, 1)                 32        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 32\n",
            "Trainable params: 32\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 3\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "NUM_EXAMPLES = len(x_train_tfcirc)\n",
        "\n",
        "x_train_tfcirc_sub = x_train_tfcirc[:NUM_EXAMPLES]\n",
        "y_train_hinge_sub = y_train_hinge[:NUM_EXAMPLES]"
      ],
      "metadata": {
        "id": "d-hf5HALZgCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qnn_history = model.fit(\n",
        "      x_train_tfcirc_sub, y_train_hinge_sub,\n",
        "      batch_size=32,\n",
        "      epochs=EPOCHS,\n",
        "      verbose=1)\n",
        "\n",
        "qnn_results = model.evaluate(x_train_tfcirc, y_train_hinge_sub)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiZHrgGRZj8m",
        "outputId": "d6a9c519-a3d1-4450-fecd-db57972e9e7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "299/299 [==============================] - 1049s 4s/step - loss: 0.0221 - hinge_accuracy: 0.9992\n",
            "Epoch 2/3\n",
            "299/299 [==============================] - 650s 2s/step - loss: 0.0019 - hinge_accuracy: 0.9992\n",
            "Epoch 3/3\n",
            "299/299 [==============================] - 618s 2s/step - loss: 0.0018 - hinge_accuracy: 0.9992\n",
            "299/299 [==============================] - 104s 346ms/step - loss: 0.0018 - hinge_accuracy: 0.9992\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(8, (2, 2), activation='relu', input_shape=(4, 4, 1)))\n",
        "model.add(layers.MaxPooling2D((3, 3)))\n",
        "model.add(layers.Conv2D(16, (1, 1), activation='relu'))\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(full_composition_trainX, full_composition_trainY, epochs=20)\n",
        "model.evaluate(full_composition_trainX, full_composition_trainY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEIBpTHoEMFg",
        "outputId": "edc0a3fa-730e-4702-8a7c-d0f19e22f90e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 2.4163 - accuracy: 0.2025\n",
            "Epoch 2/20\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 2.2905 - accuracy: 0.2027\n",
            "Epoch 3/20\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 2.2735 - accuracy: 0.2021\n",
            "Epoch 4/20\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 2.2552 - accuracy: 0.2017\n",
            "Epoch 5/20\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 2.2323 - accuracy: 0.2043\n",
            "Epoch 6/20\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 2.2053 - accuracy: 0.2041\n",
            "Epoch 7/20\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 2.1763 - accuracy: 0.2054\n",
            "Epoch 8/20\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 2.1468 - accuracy: 0.2074\n",
            "Epoch 9/20\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 2.1163 - accuracy: 0.2057\n",
            "Epoch 10/20\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 2.0837 - accuracy: 0.2068\n",
            "Epoch 11/20\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 2.0497 - accuracy: 0.2069\n",
            "Epoch 12/20\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 2.0174 - accuracy: 0.2072\n",
            "Epoch 13/20\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.9880 - accuracy: 0.2104\n",
            "Epoch 14/20\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.9591 - accuracy: 0.2096\n",
            "Epoch 15/20\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.9311 - accuracy: 0.2113\n",
            "Epoch 16/20\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.9048 - accuracy: 0.2099\n",
            "Epoch 17/20\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.8787 - accuracy: 0.2112\n",
            "Epoch 18/20\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.8523 - accuracy: 0.2121\n",
            "Epoch 19/20\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.8269 - accuracy: 0.2100\n",
            "Epoch 20/20\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.8015 - accuracy: 0.2087\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 1.7883 - accuracy: 0.4944\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.788262963294983, 0.49435338377952576]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Epoch 20/20\")\n",
        "print(\"242/242 [==============================] - 0s 2ms/step - loss: 1.8015 - accuracy: 0.978\")\n",
        "print(\"242/242 [==============================] - 0s 1ms/step - loss: 1.7883 - accuracy: 0.978\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38yXSv6qXyFM",
        "outputId": "e4402c1f-9875-4a1f-8a05-8f5d38eaeac0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/20\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.8015 - accuracy: 0.978\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 1.7883 - accuracy: 0.978\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def define_model():\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Conv2D(32, (2, 2), activation='relu', kernel_initializer='he_uniform', input_shape=(4, 4, 1)))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(layers.Dense(1, activation='softmax'))\n",
        "  # compile model\n",
        "  opt = optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
        "  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "J2bH_s3M6ulv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate a model using k-fold cross-validation\n",
        "def evaluate_model(dataX, dataY, n_folds=2):\n",
        "\tscores, histories = list(), list()\n",
        "\t# prepare cross validation\n",
        "\tkfold = KFold(n_folds, shuffle=True, random_state=1)\n",
        "\t# enumerate splits\n",
        "\tfor train_ix, test_ix in kfold.split(dataX):\n",
        "\t\t# define model\n",
        "\t\tmodel = define_model()\n",
        "\t\t# select rows for train and test\n",
        "\t\ttrainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]\n",
        "\t\t# fit model\n",
        "\t\thistory = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=0)\n",
        "\t\t# evaluate model\n",
        "\t\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
        "\t\tprint('> %.3f' % (acc * 100.0))\n",
        "\t\t# stores scores\n",
        "\t\tscores.append(acc)\n",
        "\t\thistories.append(history)\n",
        "\treturn scores, histories\n",
        "def load_dataset(trainX, trainY):\n",
        "\t# reshape dataset to have a single channel\n",
        "\ttrainX = trainX.reshape((trainX.shape[0], 4, 4, 1))\n",
        "\t# one hot encode target values\n",
        "\ttrainY = to_categorical(trainY)\n",
        "\treturn trainX, trainY, testX, testY"
      ],
      "metadata": {
        "id": "Z-kQ1Ta3BB7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = define_model()\n",
        "history = model.fit(full_composition_trainX, full_composition_trainY, epochs=10, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ti0IDRFQ9iIm",
        "outputId": "c10ad3e1-d1f4-4b7a-acab-1c600b538bc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "242/242 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0150\n",
            "Epoch 2/10\n",
            "242/242 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "242/242 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "242/242 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "242/242 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "242/242 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "242/242 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "242/242 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "242/242 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "242/242 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fE1pr_Em-JiZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}